{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "from PIL import Image\n",
    "from keras import utils\n",
    "sys.path.append('../rxrx1-utils')\n",
    "import rxrx.io as rio\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_all_train(train_csv_path='', RGB=False, num_samples=36515):\n",
    "    \n",
    "    #read in train CSV file\n",
    "    train_df = pd.read_csv(train_csv_path)\n",
    "    \n",
    "    #get targets to write out\n",
    "    y_train = train_df['sirna'].values\n",
    "    y_train = utils.to_categorical(y_train)\n",
    "    print(\"y_train shape: \", y_train.shape)\n",
    "    \n",
    "    #get df values\n",
    "    dataset = 'train'\n",
    "    experiments = train_df['experiment'].values\n",
    "    plates = train_df['plate'].values\n",
    "    wells = train_df['well'].values\n",
    "    sites = np.array([1,2])\n",
    "    channels=np.array([1,2,3,4,5,6])\n",
    "    \n",
    "    x_id = []  #list to compile x IDs\n",
    "    y_id = []  #list to compile y IDs\n",
    "    \n",
    "    for site in sites:\n",
    "        for i in tqdm_notebook(range(num_samples)):\n",
    "            site_img = np.empty((512, 512, 6), dtype=np.float16)\n",
    "            for channel in channels:\n",
    "                path = f'../data/{dataset}/{experiments[i]}/Plate{plates[i]}/{wells[i]}_s{site}_w{channel}.png'\n",
    "                site_img[:, :, channel-1] = Image.open(path)\n",
    "            \n",
    "            if RGB:\n",
    "                site_img = np.asarray(rio.convert_tensor_to_rgb(site_img, vmax=255), dtype=np.float16)\n",
    "            \n",
    "            #normalize\n",
    "            site_img /= 255\n",
    "            \n",
    "            #write out the image\n",
    "            np.save(f'../data/train_parsed_RGB/x_{experiments[i]}_{plates[i]}_{wells[i]}_s{site}', site_img, allow_pickle=True)\n",
    "            np.save(f'../data/train_parsed_RGB/y_{experiments[i]}_{plates[i]}_{wells[i]}_s{site}', y_train[i], allow_pickle=True)\n",
    "            \n",
    "            x_id.append(f'x_{experiments[i]}_{plates[i]}_{wells[i]}_s{site}')\n",
    "            y_id.append(f'y_{experiments[i]}_{plates[i]}_{wells[i]}_s{site}')\n",
    "    \n",
    "    return x_id, y_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_id, y_id = parse_all_train(train_csv_path='../data/train.csv', RGB=True, num_samples=1000)\n",
    "\n",
    "np.save('../data/x_id_RGB', x_id, allow_pickle=True)\n",
    "np.save('../data/y_id_RGB', y_id, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Control groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_all_control(train_csv_path='', RGB=False, num_samples=-1, control_type=None):\n",
    "    \n",
    "    #read in train CSV file\n",
    "    train_df = pd.read_csv(train_csv_path)\n",
    "    \n",
    "    if control_type == 'positive':\n",
    "        train_df = train_df.loc[train_df['well_type'] == 'positive_control']\n",
    "    else:\n",
    "        train_df = train_df.loc[train_df['well_type'] == 'negative_control']\n",
    "        \n",
    "    if num_samples == -1:\n",
    "        print(\"Reading all samples from dataset.\")\n",
    "        num_samples = len(train_df)\n",
    "    \n",
    "    #get targets to write out\n",
    "    num_classes = len(df.sirna.unique())\n",
    "    y_train = train_df['sirna'].values - 1108   # \"normalize\" the classes to get: [0,29]\n",
    "    y_train = utils.to_categorical(y_train, num_classes=num_classes) #apparently setting num_classes\n",
    "    print(\"y_train shape: \", y_train.shape)                          #here doesnt normalize\n",
    "    \n",
    "    #get df values\n",
    "    dataset = 'train'\n",
    "    experiments = train_df['experiment'].values\n",
    "    plates = train_df['plate'].values\n",
    "    wells = train_df['well'].values\n",
    "    sites = np.array([1,2])\n",
    "    channels=np.array([1,2,3,4,5,6])\n",
    "    \n",
    "    x_id = []  #list to compile x IDs\n",
    "    y_id = []  #list to compile y IDs\n",
    "    \n",
    "    for site in sites:\n",
    "        for i in tqdm_notebook(range(num_samples)):\n",
    "            site_img = np.empty((512, 512, 6), dtype=np.float16)\n",
    "            for channel in channels:\n",
    "                path = f'../../data/{dataset}/{experiments[i]}/Plate{plates[i]}/{wells[i]}_s{site}_w{channel}.png'\n",
    "                site_img[:, :, channel-1] = Image.open(path)\n",
    "            \n",
    "            if RGB:\n",
    "                site_img = np.asarray(rio.convert_tensor_to_rgb(site_img, vmax=255), dtype=np.float16)\n",
    "            \n",
    "            #normalize\n",
    "            site_img /= 255\n",
    "            \n",
    "            #write out the image\n",
    "            np.save(f'../../data/train_parsed_pos_control_RGB/x_{experiments[i]}_{plates[i]}_{wells[i]}_s{site}', site_img, allow_pickle=True)\n",
    "            np.save(f'../../data/train_parsed_pos_control_RGB/y_{experiments[i]}_{plates[i]}_{wells[i]}_s{site}', y_train[i], allow_pickle=True)\n",
    "            \n",
    "            x_id.append(f'x_{experiments[i]}_{plates[i]}_{wells[i]}_s{site}')\n",
    "            y_id.append(f'y_{experiments[i]}_{plates[i]}_{wells[i]}_s{site}')\n",
    "    \n",
    "    return x_id, y_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train shape:  (3944, 30)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "761c09cc94664ea1a1b2de155412bfb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3944), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d1804ef535e4bfa9eddd77e0b3ec870",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3944), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_id, y_id = parse_all_control(train_csv_path='../../data/train_controls.csv', \n",
    "                               RGB=True,\n",
    "                               num_samples=-1,\n",
    "                               control_type='positive')\n",
    "\n",
    "np.save('../../data/x_id_pos_control', x_id, allow_pickle=True)\n",
    "np.save('../../data/y_id_pos_control', y_id, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras-gpu",
   "language": "python",
   "name": "keras-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
